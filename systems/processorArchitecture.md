# Processor Architecture:
- We've been digging very close to the metal and were able to see at the machine-language level stuff C abstracted away from us. Machine language consists of sequences of very basic instructions that perform such operations as addition and checks for equality. These instructions are known collectively as an ISA (instruction set Architecture) of the processor. They also make for yet another abstraction layer which decouples the work of processor designers from that of compiler designers. Multiple processors with different architectures can have the same ISA against which compile designers improved and optimize the code generated by their compilers.
- This chapter will dig in beyond the ISA and explore the design of the processor hardware and how this hardware executes the instructions of a particular ISA. This will allow us to appreciate the hard work put in by processor designers and help us have a better understanding of how computers work. We will also see another example of abstraction at work: how the ISA appears to execute instructions in sequence, but the actual processor performs its work in parallel where multiple instructions are executed simultaneously, but programs still behave in expected fashion as if instructions run one after the other.
- The original content studies a toy processor and an associated instruction set called Y86-64. I have no interest in this Y86-64, and I will just look at general concepts and principles of logic and hardware design language (HDL) and the implementation of sequential vs. pipelined processors!! I will avoid details and just focus on general ideas.

## The Y86-64 Instruction Set Architecture:
### Instruction Encoding:
- An important topic that I found interesting in this section is *instruction encoding*. How instructions are represented in the hardware. Each instruction (in this particular Y86-64 ISA) is between 2 and 10 bytes in lengths and consists of:
	- *The initial or instruction byte* defines its type. This instruction itself is split into two parts:
		- The *code* or high-order part is used to define a family or class of instructions that do similar operations, something like JMP or MOV. 
		- The *function* low-order part defines specific stuff the instruction does, is it a `jle` or `jge`. Some instructions only have this byte such as `ret`.
	- *Register-specifier byte* is used in instructions that require one or more operands. This byte is divided into two fields. The first field is mostly used as a source and the second one as a destination and in something that has to do with computing addresses. Instructions that only have one register as an operand, can denote the empty half of the register-specifier byte with some agreed upon value like `0xF` or whatever.
	- An optional 8-byte *constant word* used in instructions that have an immediate or a memory location as one of its operands. 
- Each instruction has a unique hex value. The instruction byte can tell us what the instruction is and does and what the rest of the bytes following it do. My question is "how does the processor determine the start of an instruction?" are instructions aligned so each one is 10 bytes in length, even those that are only 1-byte in length? This is makes sense for memory, but maybe not. Because the processor can tell the size of an instruction from its starting byte, it knows exactly where to jump next.

### CISC vs RISC:
- x86-64 ISA and the x86 ISA family are deemed *CISC (complex instruction set computers)*. This type of computers came first. Instruction sets grew so big as to accommodate a large number of operations and tasks. In archaic mainframes, there were instructions that even performed high-level tasks such as evaluating polynomials and doing decimal arithmetic. Early microprocessors used limited instruction sets, but as processing power became trivial they too went the CISC way. x86 followed this path.
- Sometime in the 1980s, IBM researchers conceptualized the *RISC (reduced instruction set computers)* philosophy as an alternative approach to CISC which required powerful hardware and involved instructions that weren't even used that much. They proposed a simple instruction set that could run in cheap hardware and be organized in efficient pipelines.
The following table summarizes how CISC differs from RISC:

| CISC | RISC (Early) |
| --- | --- |
| Many many instructions | Very few instructions |
| Arithmetic/logic operations on registers and memory operands | Arithmetic and logic operations on register operands only |
|  |  |
|  |  |
|  |  |
|  |  |
|  |  |
|  |  |


## Logic Design and the Hardware Design Language:
## Sequential Y86-64 Implementations:
## General Principles of Pipelining:
## Pipelined Y86-64 Implementations: